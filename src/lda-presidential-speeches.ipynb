{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>president</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fhc</td>\n",
       "      <td>/pt-BR/discursos-artigos-e-entrevistas-categor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lula</td>\n",
       "      <td>/pt-BR/discursos-artigos-e-entrevistas-categor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  president                                               link\n",
       "0       fhc  /pt-BR/discursos-artigos-e-entrevistas-categor...\n",
       "1      lula  /pt-BR/discursos-artigos-e-entrevistas-categor..."
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "speech_links = pd.read_csv(r'C:\\Users\\FYD\\Documents\\GitHub\\lda-brazilian-books\\src\\books\\discursos-presidenciais\\discursos-presidenciais-links.txt',\n",
    "                             delimiter='|')\n",
    "\n",
    "speech_links.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process time: 407.8306894302368\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "BASE_URL = 'http://www.itamaraty.gov.br'\n",
    "\n",
    "full_link = []\n",
    "speech = []\n",
    "for link in speech_links['link']:\n",
    "    full_link.append(BASE_URL + link)\n",
    "    \n",
    "    response = requests.get(BASE_URL + link)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    speech_text = soup.find(\"div\", itemprop=\"articleBody\")\n",
    "    \n",
    "    speech.append(speech_text)\n",
    "    \n",
    "print (\"Process time: \" + str((time.time() - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>president</th>\n",
       "      <th>link</th>\n",
       "      <th>full_link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fhc</td>\n",
       "      <td>/pt-BR/discursos-artigos-e-entrevistas-categor...</td>\n",
       "      <td>http://www.itamaraty.gov.br/pt-BR/discursos-ar...</td>\n",
       "      <td>&lt;div itemprop=\"articleBody\"&gt;\n",
       "&lt;div class=\"plain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lula</td>\n",
       "      <td>/pt-BR/discursos-artigos-e-entrevistas-categor...</td>\n",
       "      <td>http://www.itamaraty.gov.br/pt-BR/discursos-ar...</td>\n",
       "      <td>&lt;div itemprop=\"articleBody\"&gt;\n",
       "&lt;p style=\"text-al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lula</td>\n",
       "      <td>/pt-BR/discursos-artigos-e-entrevistas-categor...</td>\n",
       "      <td>http://www.itamaraty.gov.br/pt-BR/discursos-ar...</td>\n",
       "      <td>&lt;div itemprop=\"articleBody\"&gt;\n",
       "&lt;p style=\"text-al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lula</td>\n",
       "      <td>/pt-BR/discursos-artigos-e-entrevistas-categor...</td>\n",
       "      <td>http://www.itamaraty.gov.br/pt-BR/discursos-ar...</td>\n",
       "      <td>&lt;div itemprop=\"articleBody\"&gt;\n",
       "&lt;p style=\"text-al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lula</td>\n",
       "      <td>/pt-BR/discursos-artigos-e-entrevistas-categor...</td>\n",
       "      <td>http://www.itamaraty.gov.br/pt-BR/discursos-ar...</td>\n",
       "      <td>&lt;div itemprop=\"articleBody\"&gt;\n",
       "&lt;p style=\"text-al...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  president                                               link  \\\n",
       "0       fhc  /pt-BR/discursos-artigos-e-entrevistas-categor...   \n",
       "1      lula  /pt-BR/discursos-artigos-e-entrevistas-categor...   \n",
       "2      lula  /pt-BR/discursos-artigos-e-entrevistas-categor...   \n",
       "3      lula  /pt-BR/discursos-artigos-e-entrevistas-categor...   \n",
       "4      lula  /pt-BR/discursos-artigos-e-entrevistas-categor...   \n",
       "\n",
       "                                           full_link  \\\n",
       "0  http://www.itamaraty.gov.br/pt-BR/discursos-ar...   \n",
       "1  http://www.itamaraty.gov.br/pt-BR/discursos-ar...   \n",
       "2  http://www.itamaraty.gov.br/pt-BR/discursos-ar...   \n",
       "3  http://www.itamaraty.gov.br/pt-BR/discursos-ar...   \n",
       "4  http://www.itamaraty.gov.br/pt-BR/discursos-ar...   \n",
       "\n",
       "                                                text  \n",
       "0  <div itemprop=\"articleBody\">\n",
       "<div class=\"plain...  \n",
       "1  <div itemprop=\"articleBody\">\n",
       "<p style=\"text-al...  \n",
       "2  <div itemprop=\"articleBody\">\n",
       "<p style=\"text-al...  \n",
       "3  <div itemprop=\"articleBody\">\n",
       "<p style=\"text-al...  \n",
       "4  <div itemprop=\"articleBody\">\n",
       "<p style=\"text-al...  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_speech_consolidated = pd.concat([speech_links,\n",
    "                                   pd.DataFrame(full_link),\n",
    "                                   pd.DataFrame(speech)], axis=1)\n",
    "\n",
    "df_speech_consolidated.columns = ['president', 'link', 'full_link', 'text']\n",
    "df_speech_consolidated.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\"\\|@,;]')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('portuguese'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "    text = text.lower() # lowercase text\n",
    "    text = text.replace(\"<div itemprop=\\\"articleBody\\\">\", \"\")\n",
    "    text = text.replace(\"<div class=\\\"plain\\\" id=\\\"parent-fieldname-text\\\">\", \"\")\n",
    "    text = text.replace(\"<p style=\\\"text-align: justify;\\\">\", \"\")\n",
    "    text = text.replace(\"<br/>\", \"\")\n",
    "    text = text.replace(\"</div>\", \"\")\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    text = text.replace(\" < p>\", \"\")    \n",
    "    text = text.replace(\".< p>\", \" \")\n",
    "    text = text.replace(\".\", \" \")\n",
    "    text = text.replace(\"<div itemprop=\\\"articlebody\\\">\", \"\")\n",
    "    text = text.replace(\"<\", \"\")\n",
    "    text = text.replace(\">\", \"\")\n",
    "     \n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    #text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
    "    return text\n",
    "    \n",
    "df_speech_consolidated['text_processed'] = df_speech_consolidated['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speech_consolidated.to_csv(r'C:\\Users\\FYD\\Documents\\GitHub\\lda-brazilian-books\\src\\books\\discursos-presidenciais\\df_speech_consolidated.csv',\n",
    "                             sep='|',\n",
    "                             index_label=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'desejo antes tudo agradecer presidente jorge sampaio esposa maria josé ritta gesto receber palácio ajuda demonstração fidalguia distingue estimado casal amigo brasil amigo brasileiros convivência presidente sampaio faz nutrir apreço cada vez maior sítios históricos portugal sinto cativo palácio ajuda onde evoca nascimento rei comum d joão vi percebo próximo palácio bélem hospedou passagem ano mostra sobre carta pêro vaz caminha cujo catálogo satisfação prefaciar juntamente presidente sampaio ressaltei prefácio prestígio hoje cerca carta dom manuel i decorre apenas dotes narrativos escrivão resulta sobretudo fato encontro etnias descrito caminha vingou vingou bem dando margem universo civilizatório profícuos caracterizado ambos lados atlântico plasticidade cultural propensão assimilar influências diversos povos sobre atualidade lastro cultural une brasil portugal gostaria dizer algumas palavras hoje noite inspirado anfitriões jorge sampaio maria ritta tanto cultivam legado humanista jaime cortesão costumava lembrar-nos portugal deslocou trópicos 1500 portugal renovava idéias substituía classicismo dogmático cultura nova base experimental certamente universalista literatura viagens confirma gosto portugueses época observação terras mares outros povos sob presunção humanidade comportava diversidade raças crenças costumes tarde veio contra-reforma inibiria livre pensar desmentiu pendor universalista cultura lusitana arte colocada sob égide fé permaneceu transitiva diálogo permanente culturas vizinhas basta lembrar vigor barroco português tanto expressivo quanto atento passava itália frança exatamente poder irradiação arte sacra lusitana beneficiaram santeiros talhadores escultores século xviii deram forma barroco brasileiro antecipou plano artístico maioridade brasil manuel costa ataíde mestre valentim nota louvor antônio francisco lisboa aleijadinho mostraram nação híbrida gestava trópicos suficientemente madura aclimatar condições locais códigos estéticos contra-reforma imprimindo leveza imagens sacras traduzindo maneira própria misticismo religiosidade tornou-se corrente leitura modernismo afastou brasil portugal semana arte moderna 1922 liberto país sintaxe lusitana penso diferente modernistas fizeram cultura brasileira passasse auto-referenciar sobretudo campos pintura literatura lembra antonio cândido deu valorização traço inscrito matriz lusitana capacidade processar diferente produzir algo novo singular deixamos utilizar ênclise assumimos vez gramática assimilação criativa legou portugal tanto mário andrade referência maior aleijadinho chamava mulato façanhudo lembra tudo gramática brasil partilha portugal faz tabula rasa diferenças nacionais desejava mentalidade autoritária hegemônica tempo cá lá buscamos luso-tropicalismo amparado atributos atemporais neutralize especificidades brasileira portuguesa gostamos daquilo singulariza cada nação queremos reduzir fado bossa-nova vice-versa preferimos caracterização faz boaventura sousa santos culturas fronteira coincidem ser permeáveis vem mantêm forte heterogeneidade interna unidade diversidade culturas tamanha vitalidade capacidade projeção portuguesa brasileira aproximação agentes culturais dá-se maneira natural sobretudo diante recursos tecnológicos hoje disponíveis convencido estado ainda papel válido desempenhar sinalizando caminhos criando incentivos oferecendo amparo institucional difusão cultura inclusive escala ampla abranja mundo lusófono daí confiança comunidade países língua portuguesa urge reconhecer significado estratégico cplp língua pátria trunfo presença internacional nítida diferenciada paradoxal possa parecer globalização trazido consigo multiculturalismo ter face própria ganhar visibilidade negociar espaço passa valorização acervo linguístico onde codificado aspiramos ser sei interesse países lusófonos áfrica ásia promover língua portuguesa sei aspiração desses países cooperação áreas ensino básico política gênero fundamental assistidos sendo hoje dia internacional mulher ressalto aqui contribuição prestada primeira conferência mulheres cplp realizada pouco salvador bahia cplp saberá cumprir ideal certo expectativa senadores josé sarney jorge bornhausen tanto contribuíram presidente república embaixador lisboa desenvolvimento comunidade iniciativas governos brasileiro português alusivas 500 anos constituem instrumentos valiosos promoção lusitanidade penso apenas acordo-quadro estaremos assinando breve atualizando vínculos normativos dois países inclusive campo científico-cultural mente ainda passos projeto resgate revolucionará pesquisa histórica sobre brasil colonial congresso brasil-portugal ano 2000 adensando diálogo academias dez diferentes áreas conhecimento brasil portugal sairão 500 anos familiarizados passado comum potencialidades dispõem futuro queremos partilhado sentimento todas personalidades envolvidas perto programação 500 anos dois lados atlântico penso aqui outros querido amigo mário soares sinto unido estima vivência política afinidade intelectual exercitamos co-autoria livro-entrevista mundo português penso vice-presidente marco maciel divide mário presidência comissão honra comemorações v centenário concluiria palavras revelando últimos meses deixaram surpreso número países amigos reivindicar ainda informalmente primazia sobre descobrimento brasil chego sentir-me lisonjeado presidir país origem tão cobiçada quero dizer queridos anfitriões assediados vão definimos ascendência brasileira portuguesa fidelidade frota cabral destemida sido porque reconhecemos desde sempre parte alma lusitana alma aberta convidativa outras culturas portuguesa sentimento perene lusitanidade peço todos levantem taças acompanhem mim ruth brinde especial saúde felicidade presidente jorge sampaio senhora aguardamos porto seguro dia 22 abril brindemos progresso bem-estar povos amizade sabemos definitiva brasil portugal obrigado p'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_speech_consolidated['text_processed'].head(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qty rows: 398, Qty columns: 5\n"
     ]
    }
   ],
   "source": [
    "# Basic counters\n",
    "print(f'Qty rows: {df_speech_consolidated.shape[0]}, Qty columns: {df_speech_consolidated.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>president</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bolsonaro</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dilma</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fhc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lula</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>temer</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   president    0\n",
       "0  bolsonaro    5\n",
       "1      dilma  191\n",
       "2        fhc    1\n",
       "3       lula  122\n",
       "4      temer   79"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show stats about the language per artist\n",
    "df_speech_consolidated.groupby(['president']).size().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-177-c40b2ff7672e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import random\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import string\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from spacy.lang.en import English\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "# Generate graphs inline in Jupyter\n",
    "%matplotlib inline\n",
    "    \n",
    "# Lock random seeds used by libraries\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "    \n",
    "# Define function to cleanup text by removing \n",
    "# personal pronouns, stopwords, and puncuation\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "punctuations = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data exploration in some specific class to see the most frequent words\n",
    "def get_word_frequency(artist):\n",
    "\n",
    "    # Word Frequency per Category\n",
    "    def cleanup_text(docs, logging=False):\n",
    "        texts = []\n",
    "        counter = 1\n",
    "        for doc in docs:\n",
    "            if counter % 1000 == 0 and logging:\n",
    "                print(\"Processed %d out of %d documents.\" % (counter, len(docs)))\n",
    "            counter += 1\n",
    "            doc = nlp(doc, disable=['parser', 'ner'])\n",
    "            tokens = [tok.lemma_.lower().strip() for tok in doc if tok.lemma_ != '-PRON-']\n",
    "            tokens = [tok for tok in tokens if tok not in stoplist and tok not in punctuations]\n",
    "            tokens = ' '.join(tokens)\n",
    "            texts.append(tokens)\n",
    "        return pd.Series(texts)\n",
    "\n",
    "    df_text = [text for text in df_raw_lyrics[df_raw_lyrics['artist'] == artist]['lyric']]\n",
    "    df_text_clean = cleanup_text(df_text)\n",
    "    df_text_clean = ' '.join(df_text_clean).split()\n",
    "    df_text_clean_counts = Counter(df_text_clean)\n",
    "    df_common_words = [word[0] for word in df_text_clean_counts.most_common(31)]\n",
    "    df_common_counts = [word[1] for word in df_text_clean_counts.most_common(31)]\n",
    "    df_common_words.pop(0)\n",
    "    df_common_counts.pop(0)\n",
    "\n",
    "    fig = plt.figure(figsize=(18,6))\n",
    "    sns.barplot(x=df_common_words, y=df_common_counts)\n",
    "    plt.title(f'Most Common Words used by {artist}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "    \n",
    "    fig.savefig(f'word_frequency_{artist}.png', format='png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
